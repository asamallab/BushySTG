{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "cf93e19a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import pickle as pkl\n",
    "from collections import Counter\n",
    "import itertools\n",
    "from itertools import combinations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "cf4b57be",
   "metadata": {},
   "outputs": [],
   "source": [
    "from BF_checkers import *\n",
    "from RoF_checker import *\n",
    "import BF_properties as BF_props\n",
    "import BF_convertors as conv\n",
    "from BF_generators import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "3c548b56",
   "metadata": {},
   "outputs": [],
   "source": [
    "def IntsToBitsFast_lr (ints, size):\n",
    "    '''\n",
    "    Source: \n",
    "    -------\n",
    "    https://stackoverflow.com/questions/\n",
    "    \n",
    "    Parameters:\n",
    "    -----------\n",
    "    ints: Numpy array of integers whose binary vectors are to be obtained\n",
    "    size: The number of bits used to encode the integers provided in array ints \n",
    "    \n",
    "    Output:\n",
    "    -------\n",
    "    Return a len(ints) X size matrix such that the MSB for each integer is the column 0 and LSB at column 'size-1'\n",
    "    '''\n",
    "    \n",
    "    return (((ints[:,None] & (1 << np.arange(size, dtype = 'int64'))[::-1])) > 0).astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "4fa176ef",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0 0 1 0 0]\n",
      " [0 0 1 0 1]]\n"
     ]
    }
   ],
   "source": [
    "ints = np.array([4, 5])\n",
    "size = 5\n",
    "x = IntsToBitsFast_lr (ints, size)\n",
    "print(x)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0d5b48ad",
   "metadata": {},
   "source": [
    "# Computing the permutations of a BF using heap algorithm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "0f9deb13",
   "metadata": {},
   "outputs": [],
   "source": [
    "def gen_heap_perms (k, f, k_list, tt):\n",
    "    '''\n",
    "    this function generates all the permutations of a BF expression\n",
    "    for a given bias and given signs on inputs and is based on a code in\n",
    "    https://stackoverflow.com/questions/29042819/heaps-algorithm-permutation-generator\n",
    "    \n",
    "    Paramters:\n",
    "    ----------\n",
    "    k: number of inputs\n",
    "    f: BF as a string of bits\n",
    "    k_list: list of the inputs\n",
    "    tt: truth table input columns as a numpy matrix\n",
    "\n",
    "    Output:\n",
    "    --------\n",
    "    returns the list of BFs as strings corresponding to all permuations of inputs\n",
    "    '''\n",
    "    \n",
    "    if k == 1:\n",
    "        yield f\n",
    "\n",
    "    else:\n",
    "        for i in range(k):\n",
    "            \n",
    "            for hp in gen_heap_perms(k-1, f, k_list, tt):\n",
    "                yield hp\n",
    "\n",
    "            if k & 1:\n",
    "                k_list[0], k_list[k-1] = k_list[k-1], k_list[0]\n",
    "                f = BF_props.bf(len(k_list), f).swap_cols((k_list[0], k_list[k-1]), tt)\n",
    "               \n",
    "            else:\n",
    "                k_list[i], k_list[k-1] = k_list[k-1], k_list[i]\n",
    "                f = BF_props.bf(len(k_list), f).swap_cols((k_list[i], k_list[k-1]), tt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "cba31d4a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['00000101', '00010001', '00000011', '00010001', '00000011', '00000101']\n"
     ]
    }
   ],
   "source": [
    "k1 = 3\n",
    "f1 = '00000101'\n",
    "k_list1 = list(range(k1, 0, -1))\n",
    "tt1 = IntsToBitsFast_lr(np.arange(2**k1), k1)\n",
    "L1 = list(gen_heap_perms (k1, f1, k_list1 ,tt1))\n",
    "print(L1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e46268de",
   "metadata": {},
   "source": [
    "# Z-parameter codes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "e4beab75",
   "metadata": {},
   "outputs": [],
   "source": [
    "## CODES FOR Z-PARAMETER COMPUTATION\n",
    "\n",
    "## COMPUTING THE ARRAY NECESSARY TO GENERATE THE Z-PARAMETER\n",
    "def left_z_count (k, f, k_inp):\n",
    "    '''\n",
    "    Parameters:\n",
    "    -----------\n",
    "    k: Number of inputs\n",
    "    f: Boolean function as a string\n",
    "    k_inp: The number of inputs (fixed)\n",
    "\n",
    "    Output:\n",
    "    -------\n",
    "    This code returns an array (n_k vector defined in the text)\n",
    "    0th element -> Cardinality of rows belong to CC-2^1 blocks\n",
    "    1st element -> Cardinality of rows belong to CC-2^2 blocks\n",
    "    2nd element -> Cardinality of rows belong to CC-2^3 blocks\n",
    "    ......\n",
    "    '''\n",
    "    if k == 1:\n",
    "        if (f == '01') or (f == '10'):\n",
    "            return np.pad([2], [0,k_inp-k], mode='constant')\n",
    "\n",
    "        else:\n",
    "            return np.pad([0], [0,k_inp-k], mode='constant')\n",
    "        \n",
    "    else:\n",
    "        p = 2**(k-1)\n",
    "        f_upper, f_lower = f[:p], f[p:]\n",
    "        a, b = set(f_upper), set(f_lower)\n",
    "        if (len(a) == 1) & (len(b) == 1) & (a != b):\n",
    "            count_array = np.array(k_inp*[0])\n",
    "            count_array[k-1] = 2*p\n",
    "            return count_array\n",
    "        else:\n",
    "            return left_z_count (k-1, f_upper, k_inp) + left_z_count (k-1, f_lower, k_inp)\n",
    "\n",
    "\n",
    "## COMPUTING THE Z-LEFT VALUE OF THE BOOLEAN FUNCTION, BASED ON THE Z_COUNT ARRAY\n",
    "def left_z_param_value (n_k_list): \n",
    "    '''\n",
    "    Parameters:\n",
    "    -----------\n",
    "    n_k_list: The array generated from the left_z_count function\n",
    "\n",
    "    Output:\n",
    "    -------\n",
    "    Z-left for the BF whose n_k_list is given as input\n",
    "    '''\n",
    "    inp_num = len(n_k_list)\n",
    "    R_k = np.array(n_k_list)/(2**inp_num)\n",
    "    z_left = R_k[0]\n",
    "    if inp_num > 1:\n",
    "        for i in range(1,inp_num):\n",
    "            z_param_term = R_k[i]\n",
    "            if z_param_term != 0:\n",
    "                for j in range(0,i):\n",
    "                    z_param_term *= (1-R_k[j])\n",
    "                z_left += z_param_term\n",
    "    return  z_left\n",
    "\n",
    "## COMPUTING THE Z-PARAMETER VALUE OF A BOOLEAN FUNCTION BY OBTAINING THE MAXIMUM (Z_MAX), MINIMUM (Z_MIN), \n",
    "## AVERAGE (Z_AVE) OF ITS Z_LEFTs OVER ALL ITS PERMUTATIONS AND Z_MID (AVERAGE OF Z_MAX AND Z_MIN)\n",
    "\n",
    "def z_param (k, f, tt, k_list):\n",
    "    '''\n",
    "    Parameters:\n",
    "    -----------\n",
    "    k: number of inputs\n",
    "    f: The Boolean function as an integer\n",
    "    tt: Truth table of the Boolean function\n",
    "    k_list: List of k inputs \n",
    "\n",
    "    Output:\n",
    "    -------\n",
    "    4 possiblities of the Z-parameter of the Boolean function, namely:\n",
    "    z_max, z_min, z_ave and z_mid\n",
    "    ''' \n",
    "    \n",
    "    f = bin(f)[2:].zfill(2**k)\n",
    "    all_perms = set(list(gen_heap_perms (k, f, k_list, tt)))\n",
    "    perm_z_values = []\n",
    "    for func in all_perms:\n",
    "        z_count = left_z_count (k, func, k)\n",
    "        z_value = left_z_param_value(z_count)\n",
    "        perm_z_values.append(z_value)\n",
    "    z_min, z_ave, z_max = min(perm_z_values), np.mean(perm_z_values), max(perm_z_values)\n",
    "    z_mid = (z_min + z_max)/2\n",
    "    return  z_max, z_min, z_ave, z_mid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "a54e49d3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.548828125"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## Computation of Z_left without using a dictioanry\n",
    "n_k_list_1 = left_z_count (5, '00110100000000000101010100001111',5)\n",
    "left_z_param_value (n_k_list_1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "d162002d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.578125, 0.390625, 0.46575520833333334, 0.484375)"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## Computation of Z-parameters for a Boolean function(Z_max, Z_min, Z_ave and Z_mid respectively)\n",
    "k2 = 5\n",
    "tt2 = IntsToBitsFast_lr(np.arange(2**k2), k2) ## function defined in heap_code\n",
    "k_list2 = list(range(k2, 0, -1))\n",
    "z_param(k2, 872437007, tt2, k_list2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1229c196",
   "metadata": {},
   "source": [
    "# Code to generate BFs at each node that satisfy the attractor (fixed point) constraints"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "d6a0cb07",
   "metadata": {},
   "outputs": [],
   "source": [
    "#This code generates the BFs which satisfy the attractor constraints at all\n",
    "#nodes of the network\n",
    "\n",
    "# The inputs to this code are:\n",
    "# 1. an attractor file (contains all nodes and attractors): attractor.tsv\n",
    "# 2. edgelist (derived from the network structure): edgelist.tsv\n",
    "# Note: The BF to a node has a truth table like this:\n",
    "# B | A | C | D(A,B,C)\n",
    "# 0   0   0   0\n",
    "# 0   0   1   0\n",
    "# 0   1   0   0\n",
    "# 0   1   1   0\n",
    "# 1   0   0   0\n",
    "# 1   0   1   0\n",
    "# 1   1   0   0\n",
    "# 1   1   1   0\n",
    "\n",
    "# The order of the variables B, A, C from Left to Right are the same as the\n",
    "#order of inputs to a node from top to bottom in the edgefile\n",
    "\n",
    "# Using the attractors, the nodes where BFs are possible are constrianed \n",
    "\n",
    "##from BF_codes import *\n",
    "##import sys\n",
    "##sys.path.append('BF_codefile')\n",
    "\n",
    "def model_data(fpath, dataset):\n",
    "    '''\n",
    "    path: a path to a file where all the data is present regarding the\n",
    "    edges and attractor files\n",
    "    returns information about the network and desired attractors\n",
    "        -node_num: a dictionary where each gene is associated with an\n",
    "        integer\n",
    "        -inedges:  a dictionary where each gene is associated with its\n",
    "        regulatory inputs\n",
    "        -signs: a list of all the signs, in the order of the nodes\n",
    "        -attr_as_matrix: the attractor specified as a matrix\n",
    "    '''\n",
    "    edges = pd.read_csv(fpath + fr'/edges_{dataset}.tsv', sep = '\\t')\n",
    "    bio_attrs = pd.read_csv(fpath + fr'/attractors_{dataset}.tsv', sep = '\\t')\n",
    "    node_num = {bio_attrs.node[i]:i for i in range(len(bio_attrs))}\n",
    "    in_edges = dict()\n",
    "    signs = dict()\n",
    "    for node in bio_attrs.node:\n",
    "        inter = edges.loc[edges[\"to\"] == node, [\"from\", \"sign\"]]\n",
    "        signs[node_num[node]] = ''.join(list(inter.sign))\n",
    "        in_edges[node_num[node]] = [node_num[ele] for ele in inter['from']]\n",
    "        if in_edges[node_num[node]] == []:\n",
    "            in_edges[node_num[node]] = [node_num[node]]\n",
    "            signs[node_num[node]] = 'a'\n",
    "            print (f'Node {node} does not have any inputs. Self loop assigned!')\n",
    "    attr_as_matrix = bio_attrs.drop('node', axis = 1).to_numpy()    \n",
    "    return node_num, in_edges, attr_as_matrix, signs\n",
    "    \n",
    "def attr_constr_funcs(fpath, dataset):\n",
    "    '''\n",
    "    path: a path to a file where all the data is present regarding the\n",
    "    edges and attractor files\n",
    "    filename: name of the particular model under consideration\n",
    "    returns a list of BFs in the order in 'node_num' which satisfy the\n",
    "    attractor constraints\n",
    "    NOTE: those rows of the truth table where a function output is replaced\n",
    "    multiple times have to be excluded from the constraint\n",
    "    '''\n",
    "    attr_constr_BFs = dict()\n",
    "    M = model_data(fpath, dataset)\n",
    "    node_num, in_edges, attr_as_matrix = M[0], M[1], M[2]\n",
    "    for node in node_num:\n",
    "        i = node_num[node]\n",
    "        x = np.array(attr_as_matrix[i], str)\n",
    "        attr_constr_rows = np.zeros(len(attr_as_matrix.T), str)\n",
    "        for in_edge in in_edges[i]:\n",
    "            attr_constr_rows = np.char.add(attr_constr_rows, np.array(attr_as_matrix[in_edge], str))\n",
    "        rows = np.array([int(ele,2) for ele in attr_constr_rows])\n",
    "        rows, x = check_conflicting_constraints(rows, x) #Check for conflicting constraints for rows at the node under consideration\n",
    "        tt = np.array (2**len(in_edges[i])*['x'])\n",
    "        tt[rows] = x\n",
    "        attr_constr_BFs[node_num[node]] = ''.join(tt)\n",
    "    return attr_constr_BFs\n",
    "\n",
    "def check_conflicting_constraints (rows, rows_output):\n",
    "    '''\n",
    "    rows: all the truth table rows which are constrainted by the attractor\n",
    "    rows_output:  all the outputs of the rows of the truth table which\n",
    "    are constrainted by the attractor\n",
    "    returns rows and the row outputs with no conflicting constraints\n",
    "    '''\n",
    "    D, remove_indices = {}, []\n",
    "    for element in set(rows):\n",
    "        D[element] = [index for index, ele in enumerate(rows) if ele == element]\n",
    "    for element in D:\n",
    "        if len(set(rows_output[D[element]])) > 1:\n",
    "            remove_indices += D[element]\n",
    "            print ('There exists a conflict at row :', element)\n",
    "    for index in sorted(remove_indices, reverse=True):\n",
    "        rows = np.delete(rows, index)\n",
    "        rows_output = np.delete(rows_output, index)\n",
    "    return rows, rows_output\n",
    "\n",
    "class constrainBF:\n",
    "    '''\n",
    "    #functionality\n",
    "    given a BF constrained at some rows, this class gives the EFs, scEUFs, scRoFs or scNCFs that satisfy those \n",
    "    constraints\n",
    "    '''\n",
    "    def __init__(self, BF, sign):\n",
    "        '''\n",
    "        #arguments\n",
    "        BF: Boolean function as a string of bits '11xx'; x can be 0 or 1\n",
    "        sign: string of 'a' and 'i'; 'ai' where 'a' is activatory and 'i' is inhibitory\n",
    "        '''\n",
    "        self.BF = BF\n",
    "        self.sign = sign\n",
    "        self.constr_rows = [ind for ind, bit in enumerate(self.BF) if bit != 'x']\n",
    "        self.fixed_bits = list(itemgetter(*self.constr_rows)(self.BF))\n",
    "\n",
    "    def with_EF (self):\n",
    "        k = len(self.sign)\n",
    "        possible_EFs = []\n",
    "        if 'x' not in self.BF:\n",
    "            if check_if(k, self.BF).is_EF():\n",
    "                possible_EFs += [int(self.BF,2)]\n",
    "            else:\n",
    "                print ('Given BF cannot be EF')\n",
    "                \n",
    "        else:\n",
    "            for func in generate(k).all_BF():\n",
    "                if check_if(k, func).is_EF():\n",
    "                    if list(itemgetter(*self.constr_rows)(func)) == self.fixed_bits:\n",
    "                        possible_EFs += [int(func,2)]\n",
    "        return possible_EFs\n",
    "\n",
    "    def with_scEUF (self):\n",
    "        k = len(self.sign)\n",
    "        uf_act_df = pd.read_csv(fr'../data/computational/UF_perms/all_UFs_k{k}.tsv', sep = '\\t')\n",
    "        euf_act_df = uf_act_df[uf_act_df['IEF']== False]\n",
    "        inh_edges = [k-index for index, s in enumerate(self.sign) if s == 'i']                \n",
    "        possible_scEUFs = []\n",
    "        \n",
    "        if 'x' not in self.BF:\n",
    "            if check_if(k, self.BF).conforms_to_edge_signs(self.sign):\n",
    "                possible_scEUFs += [int(self.BF,2)]\n",
    "            else:\n",
    "                print ('Given BF cannot be sc-EUF')\n",
    "        else:\n",
    "            for func in euf_act_df['all_UFs']:\n",
    "                func = bf(k, str(func).zfill(2**k)).swap_rows(inh_edges)\n",
    "                if list(itemgetter(*self.constr_rows)(func)) == self.fixed_bits:\n",
    "                    possible_scEUFs += [int(func, 2)]\n",
    "        return possible_scEUFs\n",
    "\n",
    "    def with_scNCF (self):\n",
    "        k = len(self.sign)\n",
    "        possible_scNCFs = []\n",
    "        inh_edges = [k-index for index, s in enumerate(self.sign) if s == 'i']\n",
    "\n",
    "        if 'x' not in self.BF:\n",
    "            if check_if(k, self.BF).conforms_to_edge_signs(self.sign):\n",
    "                if check_if(k, self.BF).is_NCF():\n",
    "                    possible_scNCFs += [int(self.BF, 2)]\n",
    "            else:\n",
    "                print ('Given BF cannot be scNCF')\n",
    "\n",
    "        else:\n",
    "            with open (fr'../data/computational/NCF_perms/all_perms_NCF{k}.txt', 'r') as file:\n",
    "                for func in file:\n",
    "                    func = bf(k, bin(int(func.strip('\\n')))[2:].zfill(2**k)).swap_rows(inh_edges)\n",
    "                    if list(itemgetter(*self.constr_rows)(func)) == self.fixed_bits:\n",
    "                        possible_scNCFs += [int(func, 2)]\n",
    "        \n",
    "        return possible_scNCFs\n",
    "\n",
    "    def with_scRoF (self):\n",
    "        k = len(self.sign)\n",
    "        possible_scrofs = []\n",
    "        inh_edges = [k-index for index, s in enumerate(self.sign) if s == 'i']\n",
    "\n",
    "        if 'x' not in self.BF:\n",
    "            if check_if(k, self.BF).conforms_to_edge_signs(self.sign):\n",
    "                if is_RoF(k, self.BF):\n",
    "                    possible_scrofs += [int(self.BF, 2)]\n",
    "            else:\n",
    "                print ('Given BF cannot be scRoF')\n",
    "            \n",
    "        else:            \n",
    "            with open (fr'../data/computational/RoF_perms/all_perms_RoF{k}.txt', 'r') as file:\n",
    "                for func in file:\n",
    "                    func = bf(k, bin(int(func.strip('\\n')))[2:].zfill(2**k)).swap_rows(inh_edges)\n",
    "                    if list(itemgetter(*self.constr_rows)(func)) == self.fixed_bits:\n",
    "                        possible_scrofs += [int(func, 2)]\n",
    "            \n",
    "        return possible_scrofs\n",
    "\n",
    "def constrain_all_nodes (BF_dict, signs, func_type_dict={}, all_type='scNCF'):\n",
    "    '''\n",
    "    Parameters:\n",
    "    -----------\n",
    "    BF_dict: is a dictionary with key as nodes and values as BFs that satisfy fixed point constraints\n",
    "    signs: the signs of the inedges for each of the nodes\n",
    "    func_type_dict: dictionary with key as nodes and values as the type of BF to be used to constrain that node\n",
    "    all_type: type of BF to be used for constraining at each node\n",
    "    \n",
    "    Output:\n",
    "    -------\n",
    "    returns a dictionary with all the nodes and the `allowed' BFs satisfying fixed point and functional constraints\n",
    "    '''\n",
    "    constr_dict = {}\n",
    "\n",
    "    if all_type != None:\n",
    "        for node in BF_dict:\n",
    "            func_type_dict[node] = all_type\n",
    "            \n",
    "    for node in BF_dict:\n",
    "        if func_type_dict[node] == 'scEUF':\n",
    "            constr_dict[node] = constrainBF(BF_dict[node], signs[node]).with_scEUF()\n",
    "            \n",
    "        elif func_type_dict[node] =='scRoF':\n",
    "            constr_dict[node] = constrainBF(BF_dict[node], signs[node]).with_scRoF()    \n",
    "\n",
    "        elif func_type_dict[node] == 'scNCF':\n",
    "            constr_dict[node] = constrainBF(BF_dict[node], signs[node]).with_scNCF()    \n",
    "\n",
    "    return constr_dict"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9ea413bd",
   "metadata": {},
   "source": [
    "# Implementation of the above code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "502148c2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "node_num: {'SCR': 0, 'PLT': 1, 'ARF': 2, 'AUXIAA': 3, 'AUXIN': 4, 'SHR': 5, 'JKD': 6, 'MGP': 7, 'WOX5': 8}\n",
      "inedges: {0: [5, 6, 7, 0], 1: [2], 2: [3], 3: [4], 4: [4], 5: [5], 6: [5, 0], 7: [5, 8, 0], 8: [5, 2, 8, 0, 7]}\n",
      "attrs: [[1 0 1 0]\n",
      " [1 1 1 1]\n",
      " [1 1 1 1]\n",
      " [0 0 0 0]\n",
      " [1 1 1 1]\n",
      " [1 1 1 0]\n",
      " [1 0 1 0]\n",
      " [0 0 1 0]\n",
      " [1 0 0 0]]\n",
      "signs: {0: 'aaia', 1: 'a', 2: 'i', 3: 'i', 4: 'a', 5: 'a', 6: 'aa', 7: 'aia', 8: 'aaaai'}\n"
     ]
    }
   ],
   "source": [
    "## From the atrractor list and edgelist creates a list dictionary of node indexing (node_num), a dictionary of the \n",
    "## inputs to each node (inedges), the attractors as a matrix (attrs) and a dictionary consisting of the signs of \n",
    "## the inputs with the same order of the inputs in inedges(signs).\n",
    "filename = 'buylla'\n",
    "path = fr'../data/data_10_Boolean_models/{filename}'\n",
    "node_num, inedges, attrs, signs = model_data(path, filename)\n",
    "print('node_num:',node_num)\n",
    "print('inedges:',inedges)\n",
    "print('attrs:',attrs)\n",
    "print('signs:',signs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "f1d45a4b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{0: '0xxxxxxx0xxxx1x1', 1: 'x1', 2: '1x', 3: 'x0', 4: 'x1', 5: '01', 6: '0x01', 7: '0xxx01x0', 8: 'xxxxxxxx0xxxxxxxxxxxxxxx0xx0xx1x'}\n"
     ]
    }
   ],
   "source": [
    "## Returns a dictionary of BFs in the order in 'node_num' which satisfy the attractor constraints (constrained rows \n",
    "## are replaced by 0 or 1 according to the attractors whereas outputs are kept 'x' where rows are not constrained by \n",
    "## the attractors)\n",
    "BF_dict = attr_constr_funcs(path, filename)\n",
    "print(BF_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "79f48a8d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1029, 69, 13, 1109, 1293, 20319, 79, 1349, 23903, 93, 1039, 3085, 17477, 3343, 3919, 17749, 21853]\n"
     ]
    }
   ],
   "source": [
    "## we can get all the functions (integer form) that satisfy the attractor constraints and fall under some specific\n",
    "## for any node in the network. For example, here we are computing the sign-conforming NCF functions at the 0'th node\n",
    "## that satisfy the attractor constraint as well.\n",
    "L = constrainBF(BF_dict[0], signs[0]).with_scNCF()\n",
    "print(L)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "d6b77944",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{0: [1029, 69, 13, 1109, 1293, 20319, 79, 1349, 23903, 93, 1039, 3085, 17477, 3343, 3919, 17749, 21853], 1: [1], 2: [2], 3: [2], 4: [1], 5: [1], 6: [1], 7: [4], 8: [2, 42, 11, 131082, 35, 522, 131586, 131075, 546, 131106, 515, 196643, 197123, 131843, 2228770, 131087, 2228266, 139810, 33686026, 33686050, 8746, 133642, 47, 2602, 33686019, 655371, 8739, 196619, 2228259, 527, 655402, 655882, 803, 2571, 779, 2831, 34212362, 35791394, 720911, 33751811, 983567, 168430122, 50529035, 3887, 983087, 134927, 572662307, 168430091, 50529059, 572662314, 34540047, 573188650, 51055371, 168430351, 985871, 52634403, 168495883, 50531087, 168495631, 724751, 34538255, 34213647, 170535466, 572728099, 51053327, 33754895, 185273103, 254750511, 51056399, 51317519, 168496911, 34541327, 168758031, 185536271, 252645167]}\n"
     ]
    }
   ],
   "source": [
    "## Returns the dictioary where the keys are the node indices as in node_num and the values are the list of all\n",
    "## functions of the type mentioned (here 'scNCF') that satisfy the attractor constraints\n",
    "func_dict = constrain_all_nodes (BF_dict, signs, func_type_dict={}, all_type='scNCF')\n",
    "print(func_dict)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a855a852",
   "metadata": {},
   "source": [
    "# Random EUF generator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "1fcbd32b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_all_forward_ele (vertices, all_vertex_neibs, ham_dist):\n",
    "    '''\n",
    "    Parameters:\n",
    "    -----------\n",
    "    vertices: the set of vertices whose influence is to be propagated\n",
    "    all_vertex_neibs: the one Hamming neighbors of all the vertices provided as a dictionary\n",
    "    ham_dist: the Hamming distance from 'vertices' to the vertex 2**k - 1\n",
    "    \n",
    "    Output:\n",
    "    -------\n",
    "    returns the list of all vertices 'ahead' of the vertices that lie in the same plane\n",
    "    '''\n",
    "    \n",
    "    if ham_dist == 0:\n",
    "        return list(set(vertices))\n",
    "\n",
    "    else:\n",
    "        new_vertices = []\n",
    "        for vertex in vertices:\n",
    "            for neib in all_vertex_neibs[vertex]:\n",
    "                if neib > vertex:\n",
    "                    new_vertices += [neib]\n",
    "                    \n",
    "        return list(set(vertices + get_all_forward_ele (new_vertices, all_vertex_neibs, ham_dist-1)))\n",
    "\n",
    "def get_all_backward_ele (vertices, all_vertex_neibs, ham_dist):\n",
    "    '''\n",
    "    vertices: the set of vertices whose influence is to be propagated\n",
    "    all_vertex_neibs: the one Hamming neighbors of all the vertices provided as a dictionary\n",
    "    ham_dist: the Hamming distance from 'vertices' to the vertex 0\n",
    "    \n",
    "    Output:\n",
    "    -------\n",
    "    returns the list of all vertices 'ahead' of the vertices that lie in the same plane\n",
    "    '''\n",
    "    \n",
    "    if ham_dist == 0:\n",
    "        return list(set(vertices))\n",
    "\n",
    "    else:\n",
    "        new_vertices = []\n",
    "        for vertex in vertices:\n",
    "            for neib in all_vertex_neibs[vertex]:\n",
    "                if neib < vertex:\n",
    "                    new_vertices += [neib]\n",
    "                    \n",
    "        return list(set(vertices + get_all_backward_ele (new_vertices, all_vertex_neibs, ham_dist-1)))\n",
    "\n",
    "def propogation_function (k, f, ind):\n",
    "    '''\n",
    "    it propogates the influence of the color of a vertex so as to satisfy the unateness property of the BF\n",
    "    k: number of inputs\n",
    "    f: BF as a truth table of 1s, 0s and xs\n",
    "    ind: index to be propogated\n",
    "    This assumes that all the regulators are activators\n",
    "    '''\n",
    "    all_vertex_neibs = bf(k, f).inps_neibs()\n",
    "    list_f = list(f)\n",
    "\n",
    "    if list_f[ind] == '0':\n",
    "        ham_dist_z = bin(0^ind).count('1')\n",
    "        z_neibs_fix = get_all_backward_ele ([ind], all_vertex_neibs, ham_dist_z)\n",
    "        for z in z_neibs_fix:\n",
    "            list_f[z] = '0'\n",
    "\n",
    "    else:\n",
    "        ham_dist_o = bin(2**k - 1^ind).count('1')\n",
    "        o_neibs_fix = get_all_forward_ele ([ind], all_vertex_neibs, ham_dist_o)\n",
    "        for o in o_neibs_fix:\n",
    "            list_f[o] = '1'\n",
    "\n",
    "    return ''.join(list_f)\n",
    "\n",
    "def generate_random_UF(k, f):\n",
    "    '''\n",
    "    Parameters:\n",
    "    -----------\n",
    "    k: Number of inputs\n",
    "    f: BF as string of size 2^k only with 'x' \n",
    "    E.g if k=2, then f = 'xxxx'\n",
    "    if k=3, then f = 'xxxxxxxx'\n",
    "    \n",
    "    Output:\n",
    "    -------\n",
    "    A UF with all inputs activatory. The UF is represented as a string of bits. \n",
    "    \n",
    "    '''\n",
    "    x_ind = []\n",
    "    for ind, bit in enumerate(f):\n",
    "        if bit == 'x':\n",
    "            x_ind += [ind]\n",
    "\n",
    "    rand_ind = random.choice(x_ind)\n",
    "    list_f = list(f)\n",
    "    list_f[rand_ind] = str(np.random.randint(0,2))\n",
    "    new_f = ''.join(list_f)\n",
    "    f = propogation_function (k, new_f, rand_ind)\n",
    "    list_f = list(f)\n",
    "    \n",
    "    if 'x' not in f:\n",
    "        return f\n",
    "\n",
    "    else:\n",
    "        return generate_random_UF (k, ''.join(list_f))\n",
    "    \n",
    "def obtained_distr_UFs(k, samp):\n",
    "    '''\n",
    "    k: number of inputs\n",
    "    samp: sample size\n",
    "    '''\n",
    "    distr = []\n",
    "    for i in range(samp):\n",
    "        f = generate_random_UF (k, 2**k *'x')\n",
    "        distr += [int(f,2)]\n",
    "    j = dict(Counter(distr))\n",
    "    return j\n",
    "\n",
    "def obtained_distr_EUFs(k, samp):\n",
    "    '''\n",
    "    k: number of inputs\n",
    "    samp: sample size\n",
    "    '''\n",
    "    distr = []\n",
    "    while len(distr) != samp:\n",
    "        f = generate_random_UF (k, 2**k *'x')\n",
    "        if check_if(k,f).is_EF():\n",
    "            distr += [int(f,2)]\n",
    "    j = dict(Counter(distr))\n",
    "    return j"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "8b78e132",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "A random UF: 0101\n",
      "Distribution of sampled random UFs: {0: 23, 5: 18, 3: 13, 15: 22, 7: 11, 1: 13}\n",
      "Distribution of sampled random EUFs: {1: 60, 7: 40}\n"
     ]
    }
   ],
   "source": [
    "# Generates a random UF\n",
    "print('A random UF:',generate_random_UF(2, 'xxxx'))\n",
    "# Gives a dictionary of frequency distribution of UFs for a specific input number and sample size\n",
    "print('Distribution of sampled random UFs:', obtained_distr_UFs(2, 100))\n",
    "# Gives a dictionary of frequency distribution of EUFs for a specific input number and sample size\n",
    "print('Distribution of sampled random EUFs:',obtained_distr_EUFs(2, 100))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "51af278f",
   "metadata": {},
   "source": [
    "# Nodewise sampling code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "3c20f312",
   "metadata": {},
   "outputs": [],
   "source": [
    "## This code returns required number of sampled functions for any node. Each function takes 4 inputs (except EF).\n",
    "## k: number of inputs to the node , f: an attractor constrained function, M: the number of functions to be sampled\n",
    "## sign: sign combination of the inputs according to the order of inputs in inedges dictionary.\n",
    "## Here two types of sampling have been considered (exact and approximated) where exact sampling is uniform sampling\n",
    "## for EFs and scEUFs. The type of sampling depends upon the number of inputs according to the given tsv file \n",
    "##'samp_type_info' provided at in the 'computational' folder inside 'data' folder. For scNCFs and scRoFs only exact\n",
    "## sampling has been used.\n",
    "\n",
    "def exact_samp_EF (k, f, M):\n",
    "    '''\n",
    "    k: number of inputs\n",
    "    f: Boolean function with fixed point constraints\n",
    "    M: number of functions to sample\n",
    "    '''\n",
    "    dummy_sign = k*'a'\n",
    "    ef_list = constrainBF(f, dummy_sign).with_EF()    \n",
    "    sampled_efs = random.choices(ef_list, k=M)\n",
    "    return sampled_efs\n",
    "\n",
    "def approx_samp_EF (k, f, M):\n",
    "    '''\n",
    "    k: number of inputs\n",
    "    f: Boolean function with fixed point constraints\n",
    "    M: number of functions to sample\n",
    "    '''\n",
    "    x_pos = [ind for ind, bit in enumerate(f) if bit == 'x']\n",
    "    list_f = list(f)\n",
    "    samp_EFs = []\n",
    "    while (M != 0):\n",
    "        for ind in x_pos:\n",
    "            list_f[ind] = str(np.random.randint(0,2))\n",
    "        if check_if(k,''.join(list_f)).is_EF() == True:\n",
    "            samp_EFs += [int(''.join(list_f),2)]\n",
    "            M -= 1\n",
    "    return samp_EFs\n",
    "\n",
    "def exact_samp_scEUF (k, f, sign, M):\n",
    "    '''\n",
    "    k: number of inputs\n",
    "    f: Boolean function with fixed point constraints\n",
    "    sign: string of length k whose elements are 'a' or 'i'. e.g. 'aiiiai'\n",
    "    M: number of functions to sample\n",
    "    '''\n",
    "    sceuf_list = constrainBF(f, sign).with_scEUF()    \n",
    "\n",
    "    sampled_sceuf = random.choices(sceuf_list, k=M)\n",
    "    return sampled_sceuf\n",
    "\n",
    "def approx_samp_scEUF (k, f, sign, M):\n",
    "    '''\n",
    "    k: number of inputs\n",
    "    f: Boolean function with fixed point constraints\n",
    "    sign: string of length k whose elements are 'a' or 'i'. e.g. 'aiiiai'\n",
    "    M: number of functions to sample\n",
    "    '''\n",
    "    fps_pos = {ind: bit for ind, bit in enumerate(f) if bit != 'x'}\n",
    "    inh_edges = [k-index for index, s in enumerate(sign) if s == 'i']\n",
    "\n",
    "    # flip the signs of the inhibitory edges and make BF activatory\n",
    "    flip_f = bf(k,f).swap_rows(inh_edges)\n",
    "    new_fps_pos = {ind: bit for ind, bit in enumerate(flip_f) if bit != 'x'}\n",
    "    for ind in list(new_fps_pos.keys()):\n",
    "        flip_f = propogation_function (k, flip_f, ind)\n",
    "\n",
    "    samp_eufs= []\n",
    "    while M != 0:\n",
    "        euf = False\n",
    "        while euf == False:\n",
    "            rand_uf = generate_random_UF(k, flip_f)\n",
    "            if check_if(k, rand_uf).is_EF():\n",
    "                euf = True\n",
    "            else:\n",
    "                euf = False\n",
    "                \n",
    "        # flip the signs of the inhibitory edges that were made activatory\n",
    "        rand_euf = bf(k, rand_uf).swap_rows(inh_edges)\n",
    "        samp_eufs += [int(rand_euf,2)]\n",
    "        M -= 1\n",
    "        \n",
    "    return samp_eufs\n",
    "\n",
    "def exact_samp_scRoF (k, f, sign, M):\n",
    "    '''\n",
    "    k: number of inputs\n",
    "    f: Boolean function with fixed point constraints\n",
    "    sign: string of length k whose elements are 'a' or 'i'. e.g. 'aiiiai'\n",
    "    M: number of functions to sample\n",
    "    '''\n",
    "    scrof_list = constrainBF(f, sign).with_scRoF()\n",
    "    \n",
    "    sampled_scrof = random.choices(scrof_list, k=M)\n",
    "    return sampled_scrof\n",
    "\n",
    "def exact_samp_scNCF (k, f, sign, M):\n",
    "    '''\n",
    "    k: number of inputs\n",
    "    f: Boolean function with fixed point constraints\n",
    "    sign: string of length k whose elements are 'a' or 'i'. e.g. 'aiiiai'\n",
    "    M: number of functions to sample\n",
    "    '''\n",
    "    scncf_list = constrainBF(f, sign).with_scNCF()    \n",
    "\n",
    "    sampled_scncf = random.choices(scncf_list, k=M)\n",
    "    return sampled_scncf"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6e1b9968",
   "metadata": {},
   "source": [
    "# Implementation of the above code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "5ad5c839",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10 sampled EF: [2186460459, 3439361570, 3662124046, 621504846, 3576418638, 3848646478, 3361020206, 1667566607, 2201425451, 2189215759]\n",
      "10 sampled RoFs: [34538255, 52634403, 139810, 252645167, 33686050, 50531087, 983567, 131843, 655371, 199179]\n"
     ]
    }
   ],
   "source": [
    "## One can generate required number of sampled functions in the following manner.\n",
    "approx_EF = approx_samp_EF (len(inedges[8]), BF_dict[8], 10)\n",
    "print('10 sampled EF:', approx_EF)\n",
    "exact_scRoF = exact_samp_scRoF (len(inedges[8]), BF_dict[8], signs[8], 10)\n",
    "print('10 sampled RoFs:', exact_scRoF)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9634aee1",
   "metadata": {},
   "source": [
    "# Nodewise enumeration of number of BFs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "f478c896",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Node IFNb does not have any inputs. Self loop assigned!\n",
      "Node TCR does not have any inputs. Self loop assigned!\n",
      "Node IL18 does not have any inputs. Self loop assigned!\n",
      "Node IL12 does not have any inputs. Self loop assigned!\n"
     ]
    }
   ],
   "source": [
    "#from mod_sel_constrBF_final import *\n",
    "\n",
    "def analysis_type (model_name):\n",
    "    '''\n",
    "    model name: A string correspond to one of the 10 reconstructed Boolean model networks (e.g. 'buylla', 't_cell',...) \n",
    "    '''\n",
    "    path = fr'../data/data_10_Boolean_models/{model_name}'\n",
    "    node_num, inedges, attrs, signs = model_data(path, model_name)\n",
    "\n",
    "    samp_info = pd.read_csv('../data/computational/samp_type_info.tsv', sep = '\\t')\n",
    "    num_node = {node_num[node]:node for node in node_num}\n",
    "    data_dict = {'Node_num': [], 'Node_name': [], 'k':[], 'EF':[], 'scEUF':[], 'scRoF':[], 'scNCF':[]}\n",
    "    for num in inedges:\n",
    "        k = len(inedges[num])\n",
    "        data_dict['Node_num'] += [num]\n",
    "        data_dict['Node_name'] += [num_node[num]]\n",
    "        data_dict['k'] += [k]\n",
    "        data_dict['EF'] += list(samp_info[samp_info['k'] == k]['EF'])\n",
    "        data_dict['scEUF'] += list(samp_info[samp_info['k'] == k]['scEUF'])\n",
    "        data_dict['scRoF'] += list(samp_info[samp_info['k'] == k]['scRoF'])\n",
    "        data_dict['scNCF'] += list(samp_info[samp_info['k'] == k]['scNCF'])\n",
    "    df = pd.DataFrame.from_dict(data_dict)\n",
    "    return df\n",
    "\n",
    "all_models = ['buylla', 't_cell', 'myeloid', 'cortical', 'drug', 'cardiac', 'sullivan', 'emt_senescent', 'corrales', 'gonadal']\n",
    "\n",
    "for model_name in all_models:\n",
    "    df = analysis_type(model_name)\n",
    "    df.to_csv(fr'../data/nodewise_enum_BF/Sampling_type_information/{model_name}_samp_type_info.tsv', sep = '\\t', index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "cc73c7e1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "buylla is completed !\n",
      "Node IFNb does not have any inputs. Self loop assigned!\n",
      "Node TCR does not have any inputs. Self loop assigned!\n",
      "Node IL18 does not have any inputs. Self loop assigned!\n",
      "Node IL12 does not have any inputs. Self loop assigned!\n",
      "Node IFNb does not have any inputs. Self loop assigned!\n",
      "Node TCR does not have any inputs. Self loop assigned!\n",
      "Node IL18 does not have any inputs. Self loop assigned!\n",
      "Node IL12 does not have any inputs. Self loop assigned!\n",
      "t_cell is completed !\n",
      "myeloid is completed !\n",
      "cortical is completed !\n",
      "drug is completed !\n",
      "cardiac is completed !\n",
      "sullivan is completed !\n",
      "emt_senescent is completed !\n",
      "corrales is completed !\n",
      "gonadal is completed !\n"
     ]
    }
   ],
   "source": [
    "import pickle as pkl\n",
    "\n",
    "def model_statistics (model_name):\n",
    "    path = fr'../data/data_10_Boolean_models/{model_name}'\n",
    "    node_num, inedges, attrs, signs = model_data(path, model_name)\n",
    "    samp_info = pd.read_csv(f'../data/nodewise_enum_BF/Sampling_type_information/{model_name}_samp_type_info.tsv', sep = '\\t')\n",
    "    BF_list = attr_constr_funcs(path, model_name)\n",
    "\n",
    "    data_dict = {'Node_num': list(samp_info['Node_num']),'EF':[], 'scEUF':[], 'scRoF':[], 'scNCF':[]}\n",
    "\n",
    "    for f_type in ['EF', 'scEUF', 'scRoF', 'scNCF']:\n",
    "        if f_type == 'EF':\n",
    "            for num in inedges:\n",
    "                if samp_info[samp_info['Node_num']== num][f_type][num] == 'exact':\n",
    "                    data_dict[f_type] += [len(constrainBF(BF_list[num], signs[num]).with_EF())]\n",
    "                else:\n",
    "                    data_dict[f_type] += ['-']\n",
    "\n",
    "        elif f_type == 'scEUF':\n",
    "            for num in inedges:\n",
    "                if samp_info[samp_info['Node_num']== num][f_type][num] == 'exact':\n",
    "                    data_dict[f_type] += [len(constrainBF(BF_list[num], signs[num]).with_scEUF())]\n",
    "                else:\n",
    "                    data_dict[f_type] += ['-']\n",
    "\n",
    "        elif f_type == 'scRoF':\n",
    "            for num in inedges:\n",
    "                if samp_info[samp_info['Node_num']== num][f_type][num] == 'exact':\n",
    "                    data_dict[f_type] += [len(constrainBF(BF_list[num], signs[num]).with_scRoF())]\n",
    "                else:\n",
    "                    data_dict[f_type] += ['-']\n",
    "\n",
    "        elif f_type == 'scNCF':\n",
    "            for num in inedges:\n",
    "                if samp_info[samp_info['Node_num']== num][f_type][num] == 'exact':\n",
    "                    data_dict[f_type] += [len(constrainBF(BF_list[num], signs[num]).with_scNCF())]\n",
    "                else:\n",
    "                    data_dict[f_type] += ['-']\n",
    "    \n",
    "    df = pd.DataFrame.from_dict(data_dict)\n",
    "    return df\n",
    "\n",
    "all_models = ['buylla', 't_cell', 'myeloid', 'cortical', 'drug', 'cardiac', 'sullivan', 'emt_senescent', 'corrales', 'gonadal']\n",
    "\n",
    "# --------------------------------------------------------------------------------------------------------------------------\n",
    "# CODE TO OBTAIN THE NUMBER OF BFs AT EACH NODE THAT SATISFY THE FIXED POINT CONSTRAINTS AND CREATE A TABLE OF THE SAME\n",
    "# --------------------------------------------------------------------------------------------------------------------------\n",
    "for model_name in all_models:    \n",
    "   df = model_statistics (model_name)\n",
    "\n",
    "   # Generate the total number of BFs possible for each ensemble and also\n",
    "   # indicate whether exhaustive computations can be carried out or not\n",
    "   tot_num, samp_row = [], []\n",
    "\n",
    "   for f_type in ['EF', 'scEUF', 'scRoF', 'scNCF']:\n",
    "       f_type_list = list(df[f_type])\n",
    "       if '-' in f_type_list:\n",
    "           tot_num += ['-']\n",
    "           samp_row += ['True']\n",
    "       else:\n",
    "            num_mod = 1\n",
    "            for ele in f_type_list:\n",
    "                num_mod *= ele\n",
    "            num = np.prod(f_type_list)\n",
    "            tot_num += [num_mod]\n",
    "            if num_mod <= 1000000:\n",
    "                samp_row += ['False']\n",
    "            else:\n",
    "                samp_row += ['True']\n",
    "\n",
    "   df.loc[len(df)] = ['Total'] + tot_num\n",
    "   df.loc[len(df)] = ['Sampled'] + samp_row\n",
    "   df.to_csv(f'../data/nodewise_enum_BF/model_statistics/{model_name}_model_stats.tsv', sep='\\t', index= False)\n",
    "   print (f'{model_name} is completed !')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "69c9340d",
   "metadata": {},
   "outputs": [],
   "source": [
    "all_models = ['buylla', 't_cell', 'myeloid', 'cortical', 'drug', 'cardiac', 'sullivan', 'emt_senescent', 'corrales', 'gonadal']\n",
    "\n",
    "for model_name in all_models:\n",
    "    df_samp_info = pd.read_csv(f'../data/nodewise_enum_BF/Sampling_type_information/{model_name}_samp_type_info.tsv', sep = '\\t')\n",
    "    df_model_stats= pd.read_csv(f'../data/nodewise_enum_BF/model_statistics/{model_name}_model_stats.tsv', sep='\\t')\n",
    "    node_name, num_inps = list(df_samp_info['Node_name']), list(df_samp_info['k'])\n",
    "    \n",
    "    df_model_stats['Node name'] = node_name + ['' , '']\n",
    "    df_model_stats['k'] = num_inps + ['', '']\n",
    "    df_model_stats['Sr No.'] = list(range(1, len(node_name)+1)) + ['Total', 'Sampled']\n",
    "    \n",
    "    df_temp = df_model_stats[['Sr No.', 'Node name', 'k', 'EF', 'scEUF', 'scRoF', 'scNCF']]\n",
    "    df_final = df_temp.rename(columns={'scEUF': 'EUF', 'scRoF': 'RoF', 'scNCF': 'NCF'}) ## To be consistent with\n",
    "    # the manuscript we have dropped the 'sc'.\n",
    "    df_final.to_csv (f'../data/nodewise_enum_BF/model_all_info/{model_name}_all_details.tsv', sep ='\\t', index = False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5c6287cd",
   "metadata": {},
   "source": [
    "# Generating the boolnet files from pkl file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "74c9e97d",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_name = 'buylla'\n",
    "f_type= 'EF'\n",
    "with open (fr'../data/data_10_Boolean_models/{model_name}/1e6_sampled_models/{f_type}_sample.pkl', 'rb') as file:\n",
    "    models = pkl.load(file)\n",
    "test_models = models[:20]\n",
    "path = fr'../data/data_10_Boolean_models/{model_name}'\n",
    "filename = fr'{model_name}'\n",
    "node_num, inedges, attrs, signs = model_data(path, filename)\n",
    "tot_func = len(test_models)\n",
    "output_path = fr'../data/data_10_Boolean_models/{model_name}/{f_type}_bnet_models/'\n",
    "os.makedirs(output_path, exist_ok=True)\n",
    "for i in range(tot_func):\n",
    "    fname = output_path + f'model_{i}.bnet'\n",
    "    BF_int_list = test_models[i]\n",
    "    conv.ints_to_BNet(fname, node_num, inedges, BF_int_list, simplify=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
